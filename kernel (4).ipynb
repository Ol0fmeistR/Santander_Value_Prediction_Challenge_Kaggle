{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n\nimport lightgbm as lgb\nfrom sklearn.model_selection import *\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom scipy.stats import mode, skew, kurtosis, entropy\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import mean_squared_error\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport dask.dataframe as dd\nfrom dask.multiprocessing import get\n\nfrom tqdm import tqdm, tqdm_notebook\ntqdm.pandas(tqdm_notebook)\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc37a766646b5993cef0bc87ad6882728dd20cb2",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/santander-value-prediction-challenge/train.csv\")\ntest = pd.read_csv(\"../input/santander-value-prediction-challenge/test.csv\")\n\ntransact_cols = [f for f in train.columns if f not in [\"ID\", \"target\"]]\ny = np.log1p(train[\"target\"]).values",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9951f375af0d5a753031352e04a85a5a12a93e18",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test[\"target\"] = train[\"target\"].mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6dcfc4df1340c38bfeac43fd4d19ba2763b3b916"
      },
      "cell_type": "markdown",
      "source": "We take time series columns from [here](https://www.kaggle.com/johnfarrell/giba-s-property-extended-result)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "95a5c734a5f982ab13ec79a74c0c304996b8eec9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "all_df = pd.concat([train, test]).reset_index(drop=True)\nall_df.columns = all_df.columns.astype(str)\nprint(all_df.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "cols = ['f190486d6', '58e2e02e6', 'eeb9cd3aa', '9fd594eec', '6eef030c1', '15ace8c9f', \n        'fb0f5dbfe', '58e056e12', '20aa07010', '024c577b9', 'd6bb78916', 'b43a7cfd5', \n        '58232a6fb', '1702b5bf0', '324921c7b', '62e59a501', '2ec5b290f', '241f0f867', \n        'fb49e4212', '66ace2992', 'f74e8f13d', '5c6487af1', '963a49cdc', '26fc93eb7', \n        '1931ccfdd', '703885424', '70feb1494', '491b9ee45', '23310aa6f', 'e176a204a', \n        '6619d81fc', '1db387535', \n        'fc99f9426', '91f701ba2', '0572565c2', '190db8488', 'adb64ff71', 'c47340d97', 'c5a231d81', '0ff32eb98']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3f297b5fca50b079bf777c88c015ade10d6aebf1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pattern_1964666 = pd.read_csv('../input/pattern-found/pattern_1964666.66.csv')\npattern_1166666 = pd.read_csv('../input/pattern-found/pattern_1166666.66.csv')\npattern_812666 = pd.read_csv('../input/pattern-found/pattern_812666.66.csv')\npattern_2002166 = pd.read_csv('../input/pattern-found/pattern_2002166.66.csv')\npattern_3160000 = pd.read_csv('../input/pattern-found/pattern_3160000.csv')\npattern_3255483 = pd.read_csv('../input/pattern-found/pattern_3255483.88.csv')\npattern_new = pd.read_csv(\"../input/newfound/new_pattern.csv\")\npattern_new1 = pd.read_csv(\"../input/newfound1/new_pattern1.csv\")\npattern_new2 = pd.read_csv(\"../input/newfound2/new_pattern2.csv\")\npattern_new3 = pd.read_csv(\"../input/newfound2/new_pattern3.csv\")\npattern_new4 = pd.read_csv(\"../input/newfound2/new_pattern4.csv\")\npattern_new5 = pd.read_csv(\"../input/newfound2/new_pattern5.csv\")\n#pattern_new6 = pd.read_csv(\"../input/newfound2/new_pattern6.csv\")\npattern_new7 = pd.read_csv(\"../input/newfound2/new_pattern7.csv\")\npattern_new8 = pd.read_csv(\"../input/newfound2/new_pattern8.csv\")\npattern_new9 = pd.read_csv(\"../input/newfound2/new_pattern9.csv\")\npattern_new10 = pd.read_csv(\"../input/newfound2/new_pattern10.csv\")\npattern_new11 = pd.read_csv(\"../input/newfound2/new_pattern11.csv\")\npattern_new12 = pd.read_csv(\"../input/newfound2/new_pattern12.csv\")\npattern_new13 = pd.read_csv(\"../input/newfound2/new_pattern13.csv\")\npattern_new14 = pd.read_csv(\"../input/newfound2/new_pattern14.csv\")\npattern_new15 = pd.read_csv(\"../input/newfound2/new_pattern15.csv\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f1528fc328e7d6e4c44c0e1a300a0dde3a1924b8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pattern_1964666.drop(['Unnamed: 0','value_count'],axis=1,inplace=True)\npattern_1166666.drop(['Unnamed: 0','value_count'],axis=1,inplace=True)\npattern_812666.drop(['Unnamed: 0','value_count'],axis=1,inplace=True)\npattern_2002166.drop(['Unnamed: 0','value_count'],axis=1,inplace=True)\npattern_3160000.drop(['Unnamed: 0','value_count'],axis=1,inplace=True)\npattern_3255483.drop(['Unnamed: 0','value_count'],axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2e0eed16eada664d156a7ca0b6c95728c4a38b14",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "pattern_1166666.rename(columns={'8.50E+43': '850027e38'},inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10732e8b2160cc845c9bf74a6ec16fd771f91bc9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "l=[]\nl.append(pattern_1964666.columns.values.tolist())\nl.append(pattern_1166666.columns.values.tolist())\nl.append(pattern_812666.columns.values.tolist())\nl.append(pattern_2002166.columns.values.tolist())\nl.append(pattern_3160000.columns.values.tolist())\nl.append(pattern_3255483.columns.values.tolist())\nl.append(pattern_new.columns.values.tolist())\nl.append(pattern_new1.columns.values.tolist())\nl.append(pattern_new2.columns.values.tolist())\nl.append(pattern_new3.columns.values.tolist())\nl.append(pattern_new4.columns.values.tolist())\nl.append(pattern_new5.columns.values.tolist())\nl.append(pattern_new7.columns.values.tolist())\nl.append(pattern_new8.columns.values.tolist())\nl.append(pattern_new9.columns.values.tolist())\nl.append(pattern_new10.columns.values.tolist())\nl.append(pattern_new11.columns.values.tolist())\nl.append(pattern_new12.columns.values.tolist())\nl.append(pattern_new13.columns.values.tolist())\nl.append(pattern_new14.columns.values.tolist())\nl.append(pattern_new15.columns.values.tolist())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "894fdefbe479e983b85100a9f0dc0d06af279249"
      },
      "cell_type": "markdown",
      "source": "Updating this function on the basis of the hint provided by Paradox [here](http://www.kaggle.com/c/santander-value-prediction-challenge/discussion/61472#363394)."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2664b88d70c76fde0df57ca6f22f75997f72cb00",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def _get_leak(df, cols,extra_feats, lag=0):\n    f1 = cols[:((lag+2) * -1)]\n    f2 = cols[(lag+2):]\n    for ef in extra_feats:\n        f1 += ef[:((lag+2) * -1)]\n        f2 += ef[(lag+2):]\n    \n    d1 = df[f1].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'})\n    d1.to_csv('extra_d1.csv')\n    d2 = df[f2].apply(tuple, axis=1).to_frame().rename(columns={0: 'key'}) \n\n    d2['pred'] = df[cols[lag]]\n#     d2.to_csv('extra_d2.csv')\n    #d2 = d2[d2.pred != 0] ### to make output consistent with Hasan's function\n    d3 = d2[~d2.duplicated(['key'], keep=False)]\n    d4 = d1[~d1.duplicated(['key'], keep=False)]\n    d5 = d4.merge(d3, how='inner', on='key')\n    \n    d6 = d1.merge(d5, how='left', on='key')\n    d6.to_csv('extra_d6.csv')\n    \n    return d1.merge(d5, how='left', on='key').pred.fillna(0)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d61c75092518f50a879e9e3d5883ab752f73912b",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def compiled_leak_result():\n    \n    max_nlags = len(cols)-2\n    train_leak = train[[\"ID\", \"target\"] + cols]\n    train_leak[\"compiled_leak\"] = 0\n    train_leak[\"nonzero_mean\"] = train[transact_cols].apply(\n        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n    )\n    scores = []\n    leaky_value_counts = []\n    leaky_value_corrects = []\n    leaky_cols = []\n    \n    for i in range(max_nlags):\n        c = \"leaked_target_\"+str(i)\n        print('Processing lag', i)\n        train_leak[c] = _get_leak(train, cols,l, i)\n        \n        leaky_cols.append(c)\n        train_leak = train.join(\n            train_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n            on=\"ID\", how=\"left\"\n        )[[\"ID\", \"target\"] + cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]\n        zeroleak = train_leak[\"compiled_leak\"]==0\n        train_leak.loc[zeroleak, \"compiled_leak\"] = train_leak.loc[zeroleak, c]\n        leaky_value_counts.append(sum(train_leak[\"compiled_leak\"] > 0))\n        _correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n        leaky_value_corrects.append(_correct_counts*1.0/leaky_value_counts[-1])\n        print(\"Leak values found in train\", leaky_value_counts[-1])\n        print(\n            \"% of correct leaks values in train \", \n            leaky_value_corrects[-1]\n        )\n        tmp = train_leak.copy()\n        tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n        print('Na count',tmp.compiled_leak.isna().sum())\n        scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n        print(\n            'Score (filled with nonzero mean)', \n            scores[-1]\n        )\n    result = dict(\n        score=scores, \n        leaky_count=leaky_value_counts,\n        leaky_correct=leaky_value_corrects,\n    )\n    return train_leak, result",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "68f3fde6e5e9d274a4de6ef0975bbb4b682d5e85",
        "_kg_hide-output": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_leak, result = compiled_leak_result()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d904afe6c581aa250592432402977b1ab2b3ede",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "result = pd.DataFrame.from_dict(result, orient='columns')\nresult.T",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "629ec0c6ee122fd82bf40f09a55a3f6f8f6c7fdf",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "result.to_csv('train_leaky_stat.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "42bfb7c9b41f687c189229f83cc6c8c7fd100536",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "train_leak.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "15e49a1e6f3d95150a4114edca7d3ae910bc6ee3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "best_score = np.min(result['score'])\nbest_lag = np.argmin(result['score'])\nprint('best_score', best_score, '\\nbest_lag', best_lag)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "290bdece0f2029880f805b9968077a4f0880b1ea"
      },
      "cell_type": "code",
      "source": "def compiled_leak_result_test():\n    \n    max_nlags = len(cols)-2\n    test_leak = test[[\"ID\", \"target\"] + cols]\n    test_leak[\"compiled_leak\"] = 0\n    test_leak[\"nonzero_mean\"] = test[transact_cols].apply(\n        lambda x: np.expm1(np.log1p(x[x!=0]).mean()), axis=1\n    )\n    #scores = []\n    leaky_value_counts = []\n    #leaky_value_corrects = []\n    leaky_cols = []\n    \n    for i in range(max_nlags):\n        c = \"leaked_target_\"+str(i)\n        print('Processing lag', i)\n        test_leak[c] = _get_leak(test, cols,l, i)\n        \n        leaky_cols.append(c)\n        test_leak = test.join(\n            test_leak.set_index(\"ID\")[leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]], \n            on=\"ID\", how=\"left\"\n        )[[\"ID\", \"target\"] + cols + leaky_cols+[\"compiled_leak\", \"nonzero_mean\"]]\n        zeroleak = test_leak[\"compiled_leak\"]==0\n        test_leak.loc[zeroleak, \"compiled_leak\"] = test_leak.loc[zeroleak, c]\n        leaky_value_counts.append(sum(test_leak[\"compiled_leak\"] > 0))\n        #_correct_counts = sum(train_leak[\"compiled_leak\"]==train_leak[\"target\"])\n        #leaky_value_corrects.append(_correct_counts*1.0/leaky_value_counts[-1])\n        print(\"Leak values found in test\", leaky_value_counts[-1])\n        #print(\n            #\"% of correct leaks values in train \", \n            #leaky_value_corrects[-1]\n        #)\n        tmp = test_leak.copy()\n        tmp.loc[zeroleak, \"compiled_leak\"] = tmp.loc[zeroleak, \"nonzero_mean\"]\n        print('Na count',tmp.compiled_leak.isna().sum())\n        #scores.append(np.sqrt(mean_squared_error(y, np.log1p(tmp[\"compiled_leak\"]).fillna(14.49))))\n        #print(\n            #'Score (filled with nonzero mean)', \n            #scores[-1]\n        #)\n    #result = dict(\n        #score=scores, \n        #leaky_count=leaky_value_counts,\n        #leaky_correct=leaky_value_corrects,\n    #)\n    return test_leak #result",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "439c61381a5204c70cb005d7048be88bec55460d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_leak = compiled_leak_result_test()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "35147c0cfc220fa74f2dcc7ccd86ec6b8e535cee",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_leak.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3633acacebfb696fb7b84d0d8120205ab25112cb",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "test_leak.loc[test_leak[\"compiled_leak\"] == 0, \"compiled_leak\"] = test_leak.loc[test_leak[\"compiled_leak\"] == 0, \"nonzero_mean\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a833ef0ff9ab476322a87c20a49836c7802b55a0",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#submission\nsub = test_leak[[\"ID\"]]\nsub[\"target\"] = test_leak[\"compiled_leak\"]\nsub.to_csv(\"improved_submission_with_leaks_patterns.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "b3140ac5bdcfd5eefa61e9da9f036e7f2714de3e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}